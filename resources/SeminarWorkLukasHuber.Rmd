---
title: "Topic Modelling of a Medical Online Board"
author: "Lukas Huber"
date: "19. February 2015"
output: html_document
bibliography: literature.bib
---

#Abstract

#Introduction
The information about diseases found online can be investigated and analyzed to create new insights.

But the content is human readable in an online board, where people are discussing their sickness and others share their knowledge or story and give recommendations. 

The challenge is to analyze the free text in a way to use the huge amount of data further on.
Topic modeling is a type of statistical model to discover abstract "topics" in a collection of documents.

The Goal of this paper is to show the process of collecting the information, finding the models, and look at the topic modeled result.

##Terms
- A *word* is the basic discrete unit from a *vocabulary* indexed {1,...,V}
- A *document* is a sequence of *N* words **w** = _(w~1~,w~2~,...,w~n~)_
- A *corpus* is a collection of *M* documents **D**= _(**w**~1~,**w**~2~,...,**w**~m~)_


##Web Scraping

##Topic Models

##Latent Dirichlet allocation
Latent Dirichlet allocation (LDA) is a generative probabilistic model of a corpus. LDA is a generalization of *PLSI* (Probabilistic latent semantic indexing [@Hofmann1999])

[@Blei2012a]


[@Grun2011]


#Methods
Data collection
[@Rolf]
Bayesian model selection

#Results

#Discussion
Word position and sturcture is not covered, only counts are important.
The use of meta data like author, date, can show connections between topics and authors, as well as the relation between the documents.

Pachinko allocation
better stopwords

```{r}
summary(cars)
```

You can also embed plots, for example:

```{r, echo=FALSE}
plot(cars)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

# References
